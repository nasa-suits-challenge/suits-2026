# Athena Voice AIA â€” Implementation Plan

---

## 1) System Diagram
```
Mic â†’ VAD â†’ Wake â†’ ASR â†’ Intent Router (FSM + Local LLM) â†’ TTS â†’ Speaker/HUD
                          â”‚
                          â”œâ”€â”€ Telemetry (TSS via WebSocket JSON/GeoJSON)
                          â”‚
               HAL (openai/gpt-oss-120B via vLLM/TGI)  â†”  Earth (high RTT)
```
- **Onâ€‘Suit Core** handles all EVAâ€‘critical functions locally.  
- **HAL** provides optional heavy reasoning; returns **short, templated directives**.  
- **Earth** performs longâ€‘horizon analytics; never on the critical path.

---

## 2) Runtime Components
| Component | Responsibility |
|---|---|
| Context Manager | Builds **context envelope** each turn from TSS + local state |
| Intent Router | Finiteâ€‘state per EVA mode; maps ASR â†’ tool plan |
| Tool Executor | Validates schema + phase; executes tools with timeouts |
| Evidence Binder | Ensures `say()` slots are backed by tool/context values |
| Speech Loop | Piper TTS; HUD sync and alert priorities |
| Link Monitor | Tracks Green/Yellow/Red QoS; gates HAL tools |

---

## 3) Local LLM Prompt (Rules)
```
You are the on-suit AIA on a critical NASA space mission.

Rules (default):
1) Use ONLY tools listed in caps.tools_allowed for this turn.
2) Treat eva_mode as a finite-state controller; refuse intents not valid in this mode.
3) Any write/actuation requires ptt_held=true OR an explicit confirm intent.
4) Speak via say(template_id, slots) ONLY; no free-form prose.
5) Bind every spoken slot to values from the current context envelope OR tool results from this turn,
   OR a validated tool result cached within the last 10 seconds (must include its timestamp).
6) If you need a capability that is not allowed, set request_capability to the tool name and wait.
7) If data is missing or confidence is low, choose a refusal/clarify template (e.g., need_repeat, need_confirm).

Output format (strict JSON):
{
  "intent": "...",
  "tool_calls": [ { "name": "...", "args": { ... } }, ... ],
  "template": { "id": "...", "slots": { ... } },
  "request_capability": "optional_tool_name_if_needed"
}
```
---

## 4) Tool API (core subset)
All tools are JSONâ€‘schemaâ€‘validated and **phaseâ€‘whitelisted**.

- `get_telemetry(fields: string[]) â†’ {timestamp, data:{...}}` *(read)*  
- `get_checklist_step(procedure_id, step_index) â†’ {step:{index,text,requires_confirm}}` *(read)*  
- `advance_step(procedure_id, from_index) â†’ {ok,to_index}` *(write, requires PTT/confirm)*  
- `repeat_step(procedure_id, index) â†’ {ok}` *(read)*  
- `set_breadcrumb(label) â†’ {ok, marker_id}` *(write, requires PTT/confirm)*  
- `get_bearing_to(marker_id) â†’ {bearing_deg, distance_m}` *(read)*  
- `list_markers() â†’ {markers:[...]}` *(read)*  
- `say(template_id, slots) â†’ {ok}` *(deterministic TTS wrapper)*

**HAL tools** (granted on request, link=GREEN):  
- `plan_route(from,to,constraints) â†’ {waypoints:[...]}` *(read)*  
- `summarize_recent(window_min) â†’ {bullets:[...]}` *(read)*  
- `rerank_asr(candidates[],context) â†’ {text}` *(read)*

---

## 5) Templates
Examples (see `docs/templates.json` for full set):
- `status_o2`: `"Primary Oâ‚‚ {o2_primary_pct}% â€” Secondary {o2_secondary_pct}%."`
- `bearing_simple`: `"Bearing {bearing_deg} degrees, {distance_m} meters."`
- `step_read`: `"Step {index}: {text}."`
- `step_advanced`: `"Step {from_index} complete. Proceed to step {to_index}."`
- `marker_set`: `"Marker {label} set."`

**Validator:** Each slot must come from the immediate turn's tool result or context.

---

## 6) Models & Config
- **VAD:** Silero/WebRTC VAD (<1 ms per 10 ms frame)  
- **Wake:** Porcupine / OpenWakeWord (phrase: â€œAthena â€¦â€)  
- **ASR:** Fasterâ€‘Whisper baseâ€‘en (int8), 16 kHz mono; partials every 100â€“200 ms  
- **Local LLM:** Llamaâ€‘3.1â€‘8B Q4_K_M (ctx 1024â€“2048, `n_predict â‰¤ 16`, `temp 0.2â€“0.4`, `top_p 0.9`, `repeat_penalty 1.1`)  
- **TTS:** Piper; preâ€‘bake frequent prompts as audio for instant playback  
- **HAL LLM:** openai/gptâ€‘ossâ€‘120B on DGX Spark; vLLM/TGI; short templated outputs

**CPU pinning:** Reserve 2 cores for ASR/TTS/UI; pin LLM to remaining cores.  
**KV cache discipline:** limit context to avoid RAM creep; sliding window for local LLM.

---

## 7) Latency Budget
| Stage | Target |
|---|---|
| VAD + Wake | <100 ms |
| ASR partial | 100â€“200 ms |
| FSM Intent | <5 ms |
| TTS (short line) | 60â€“120 ms |
| Local LLM (8B Q4, 10 tok) | 400â€“800 ms |
| HAL offload roundâ€‘trip | 800â€“1500 ms (LAN) |
| Earth roundâ€‘trip | 2600+ ms (informational only) |

**Default path:** FSM/noâ€‘LLM stays **â‰¤ 250â€“450 ms** endâ€‘toâ€‘end.

---

## 8) Safety & Guardrails
- Phaseâ€‘bounded whitelists; outâ€‘ofâ€‘phase â†’ refusal template.  
- **PTT/confirm** required for any write/step advance.  
- Tool timeouts (400â€“500 ms); on timeout â†’ safe refusal.  
- Full audit log: `{intent, tool, args, result_hash, template_id}`.  
- Cryptographic channel to HAL (mTLS on HTTP/3/QUIC).

---

## 9) Testing Matrix (HITL)
| Test | Metric | Pass Criteria |
|---|---|---|
| Latency | Micâ†’Speech | â‰¤0.5 s (deterministic) |
| Accuracy | WER / Intent F1 | <10 % / >95 % |
| Robustness | Falseâ€‘wake / misâ€‘intent | <1 % / <5 % |
| Network | Green/Yellow/Red continuity | 0 critical losses |
| Usability | PTT with gloves | 100 % actuation gated |
| Evidence | Slot validation | 100 % bound to tools |

Night/noise trials and link flapping (Greenâ†’Redâ†’Green) are included; recovery must be seamless.

---

## 10) Deployment Plan
1. **Dev (Fall 2025):** Local loop + FSM + TSS simulator; latency/WER baselines.  
2. **Integration (Spring 2026):** HAL RPCs; capabilityâ€‘onâ€‘request; full HITL battery.  
3. **Field (May 2026):** Connect to SUITSNET; night Rock Yard test; metrics capture.

---

## 11) File Map
```
docs/PRD.md
docs/IMPLEMENTATION.md
docs/tools.json
docs/templates.json
runtime/planner_test.py
```


## ðŸ§  GPT-OSS-20B â€” Local Suite Model Spec (Recommended Upgrade)

**Model:** `gpt-oss-20b`  
**License:** Apache 2.0 (fully open-source)  
**Size:** 20 billion parameters  
**Memory footprint:** â‰ˆ 15 â€“ 16 GB (fits a 16 GB device with quantization, e.g. Q4_K_M or Q5_K_M)  
**Runtime:** Compatible with `llama.cpp`, `vLLM`, `Ollama`, or OpenAI-compatible API endpoints  
**Context:** up to 32 K tokens  
**Latency (local CPU + GPU hybrid):** ~ 1 s for â‰¤ 10 tokens on a laptop-class GPU; < 700 ms on a desktop RTX 3060/4070  
**Languages:** English-tuned but strong multilingual generalization  
**Quantizations:** GGUF Q4_K_M (â‰ˆ 10 GB), Q5_K_M (â‰ˆ 13 GB), BF16 (â‰ˆ 32 GB full precision)

### ðŸ”§ Native Capabilities
- âœ… **Tool use / Function calling:** OpenAI-style schema (`tools`, `tool_choice`, `tool_calls`)  
- âœ… **Web browsing & retrieval hooks:** designed for plug-in agent runtimes  
- âœ… **Structured JSON / grammar-constrained output**  
- âœ… **Strong short-context reasoning & low hallucination**  
- âœ… **Drop-in OpenAI API compatibility** for local deployments

### ðŸª¶ Recommended EVA Configuration
| Component | Setting |
|------------|----------|
| **Runtime** | `llama.cpp-server` or `Ollama` with OpenAI-compat API |
| **Context** | 2 K â€“ 4 K active (sliding) |
| **Temp / Top-P** | 0.2 â€“ 0.4 / 0.9 |
| **Max new tokens** | â‰¤ 16 |
| **Function call interface** | native `tools` schema |
| **Speech out** | templates only (`say(template_id, slots)`) |
| **Safety** | phase-aware; `ptt_held` or confirm intent required for writes |

### ðŸ›°ï¸ Comparison

| Model | Params | Function Calling | License | Offline Perf (8 core + GPU) | Notes |
|-------|---------|------------------|----------|-------------------------------|-------|
| **GPT-OSS-20B** | 20B | âœ… Native (OpenAI schema) | Apache 2.0 | 400 â€“ 900 ms | Best open function-caller w/ license freedom |
| **Llama 3.1 8B** | 8B | Via grammar/Ollama | Meta license | 300 â€“ 700 ms | Lightweight, deterministic |
| **Qwen 2.5 14B** | 14B | Native (OpenAI schema) | Apache 2.0 | 500 â€“ 1000 ms | Excellent tool agent; more RAM |
| **Gemma 3 12B** | 12B | Partial (prompt based) | Apache 2.0 | 600 â€“ 1100 ms | Great context window; less tool-tuned |


